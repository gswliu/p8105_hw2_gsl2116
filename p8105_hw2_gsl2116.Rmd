---
title: "p8105_hw2_gsl2116"
author: "Grace Liu"
date: "10/05/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
library(ggridges)
```

## Problem 1
```{r clean_transit}
transit_data = read_csv(file = "./HW_Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, route1:route11, entry, entrance_type, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```
This dataset has 1868 observations and 18 variables (dimensions = 1868 x 18). From the original 32 variables in the dataset, I have only kept 18 that are of interest in my analysis: line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. This data set includes character, integer, logical, and numeric variable types.  

#### How many distinct stations are there?
```{r distinct_stations, eval=FALSE}
nrow(distinct(transit_data, line, station_name))
```
There are `r nrow(distinct(transit_data, line, station_name))` distinct train stations.

#### How many stations are ADA compliant?
```{r ada_stations, eval=FALSE}
nrow(distinct(filter(transit_data, ada == TRUE), line, station_name))
```
Of these `r nrow(distinct(transit_data, line, station_name))` distinct stations, `r nrow(distinct(filter(transit_data, ada == TRUE), transit_data, line, station_name))` are ADA compliant.

#### What proportion of station entrances / exits without vending allow entrance?
```{r entry_stations}
transit_data %>%
  group_by(vending, entry) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))
```
Of station entrances/exits without vending, 37.7% allow entrance.

## Problem 2
```{r clean_mrtrash}
mrtrash_data =
  read_excel("./HW_Data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
             sheet = "Mr. Trash Wheel", skip = 1, col_names = TRUE, range = "A2:N256") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

There are a total of 215 observations and 14 variables. This dataset provides data on the amount of plastic and glass bottles, cigarette butts, grocery and chip bags, polystyrene, and sports balls found in dumpsters between 2014 and 2017. The average weight (across all years) of trash within the dumpsters was `r mean(mrtrash_data$weight_tons)` tons. In 2017, there was an average of `r mean(mrtrash_data$weight_tons[mrtrash_data$year == 2017], na.rm = TRUE)` tons of trash in dumpsters. In 2016, the median number of sports balls in a dumpster was `r median(mrtrash_data$sports_balls[mrtrash_data$year == 2016], na.rm = TRUE)`. Within this period there were `r sum(mrtrash_data$homes_powered)` total homes powered by the trash found in dumpsters. In 2017 alone, there were `r round(sum(mrtrash_data$homes_powered[mrtrash_data$year == 2017], na.rm = TRUE))` homes powered.

```{r join_precip}
precip_2016 =
  read_excel("./HW_Data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
             sheet = "2016 Precipitation", skip = 1, col_names = TRUE, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016)

precip_2017 =
  read_excel("./HW_Data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
             sheet = "2017 Precipitation", skip = 1, col_names = TRUE, range = "A2:B14") %>%
  janitor::clean_names() %>% 
  drop_na(total) %>% 
  mutate(year = 2017)

precip_data =
  full_join(precip_2016, precip_2017) %>% 
  mutate(month = month.name[month])
```
There are a total of 24 observations (one per month in 2016 and 2017) and 3 variables in the combined precipitation dataset. The total precipitation was `r sum(precip_data$total[precip_data$year == 2017])` inches in 2017 and `r sum(precip_data$total[precip_data$year == 2016])` inches in 2016. The average amount of precipitation, rounded to the nearest inch, was `r round(mean(precip_data$total[precip_data$year == 2017]))` inches in 2017 and `r round(mean(precip_data$total[precip_data$year == 2016]))` inches in 2016.

## Problem 3
```{r brfss_setup, include=FALSE}
devtools::install_github("p8105/p8105.datasets") # install.packages("devtools")
library(p8105.datasets)
```

```{r clean_brfss}
brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value)
```

There are `r nrow(distinct(brfss_data, locationdesc))` unique locations included in the dataset. There are `r nrow(distinct(brfss_data, locationabbr))` states (plus the District of Columbia) represented. The state that is observed the most is `r names(which.max(table(brfss_data$locationabbr)))`. The median of the “Excellent” response value in 2002 is `r median(brfss_data$Excellent[brfss_data$year == 2002], na.rm = TRUE)`.

### Graphs
#### “Excellent” response values, 2002
“Excellent” response values in the year 2002
```{r}
filter(brfss_data, year == 2002) %>% 
  ggplot(aes(x = Excellent)) +
  geom_histogram() +
  theme_minimal()
```

#### Proportion of “Excellent” response values
Proportion of “Excellent” response values in New York County and Queens County (in NY State), from 2002 to 2010
```{r}
ny_excellent = brfss_data %>% 
  filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County")

ggplot(ny_excellent, aes(x = year, y = Excellent)) +
  geom_point(aes(color = locationdesc)) +
  labs(title = "Proportion of 'Excellent' Response Values",
       y = "Proportion of responses (%)",
       x = "Year") +
  viridis::scale_color_viridis(name = "County", discrete = TRUE) +
  theme_minimal() +
  theme(legend.position = "bottom")
```